# Dreambooth (single-subject training)

游리游릭游댮
## Background

The term Dreambooth refers to a technique developed by Google to inject subjects by finetuning them into a model using a small set of high quality images ([paper](https://dreambooth.github.io))

In the context of fine-tuning, Dreambooth adds new techniques to help prevent model collapse due to eg. overfitting or artifacts.

### Regularisation images

Regularisation images are typically generated by the model you are training, using a token that resembles your class.

They do not **have** to be synthetic images generated by the model, but this possibly has better performance than using real data (eg. photographs of real persons).

Example: If you are training in images of a male subject, your regularisation data would be photographs or synthetic generated samples of random male subjects.

> 游릭 Regularisation images can be configured as a separate dataset, allowing them to mix evenly with your training data.

### Rare token training

A concept of dubious value from the original paper was to do a reverse search through the model's tokenizer vocabulary to find a "rare" string that had very little training associated to it.

Since that time, the idea has evolved and debated, with an opposing camp deciding to train against a celebrity's name that looks similar enough, as this requires less compute.

> 游리 Rare token training is supported in SimpleTuner, but there's no tool available to help you find one.

### Prior preservation loss

The model contains something called a "prior" which could, in theory, be preserved during Dreambooth training. In experiments with Stable Diffusion however, it didn't seem to help - the model just overfits on its own knowledge.

> 游댮 Prior preservation loss is not supported in SimpleTuner, all regularisation data is treated as if it were usual training data.

## Setup

Following the [tutorial](/TUTORIAL.md) is required before you can continue into Dreambooth-specific configuration.

Recommended configuration values for `sdxl-env.sh` or `sd2x-env.sh`:

```bash
TRAIN_BATCH_SIZE=1

LEARNING_RATE=4e-6
LEARNING_RATE_END=4e-7

OPTIMIZER=adamw-bf16

MAX_NUM_STEPS=1000
NUM_EPOCHS=25

VALIDATION_STEPS=100
VALIDATION_PROMPT="a photograph of subjectname"

DATALOADER_CONFIG="multidatabackend-dreambooth.json"
```

Inside our dataloader config `multidatabackend-dreambooth.json`, it will look something like this:

```json
[
    {
        "id": "subjectname-data",
        "type": "local",
        "instance_data_dir": "/training/datasets/subjectname",
        "caption_strategy": "instanceprompt",
        "instance_prompt": "subjectname",
        "cache_dir_vae": "/training/vae_cache/subjectname",
        "repeats": 1,
        "crop": false,
        "resolution": 0.5,
        "resolution_type": "area",
        "minimum_image_size": 0.25
    },
    {
        "id": "regularisation-data",
        "type": "local",
        "instance_data_dir": "/training/datasets/regularisation",
        "caption_strategy": "instanceprompt",
        "instance_prompt": "a picture of a man",
        "cache_dir_vae": "/training/vae_cache/regularisation",
        "repeats": 10,
        "ignore_epochs": true,
        "resolution": 0.5,
        "resolution_type": "area",
        "minimum_image_size": 0.5
    },
    {
        "id": "textembeds",
        "type": "local",
        "dataset_type": "text_embeds",
        "default": true,
        "cache_dir": "/training/text_cache"
    }
]
```

Some key values have been tweaked to make training a single subject easier:

- We now have two datasets configured. Regularisation data is optional, and training may work better without it. You can remove that dataset from the list if desired.
- Resolution is set to `0.5` which will be approximately 512x512 training, which goes faster for SDXL models, and is the native resolution for 1.5 models.
- Minimum image size is set to `0.25` which will allow us to upsample some smaller images, which might be needed for datasets with a few important but low resolution images.
- `caption_strategy` is now `instanceprompt`, which means we will use `instance_prompt` value for every image in the dataset as its caption.

For a regularisation dataset:

- Set `ignore_epochs=true`, which will ensure this dataset does not count toward a "finished epoch"
- Set `repeats` high enough that this dataset will never stop being sampled
- `minimum_image_size` has been increased to ensure we don't introduce too many low-quality artifacts

## Selecting an instance prompt

As mentioned earlier, the original focus of Dreambooth was the selection of rare tokens to train on.

Alternatively, one might use the real name of their subject, or a 'similar enough' celebrity.

After a number of training experiments, it seems as though a 'similar enough' celebrity is the best choice, especially if prompting the model for the person's real name ends up looking dissimilar.